# MCP-сервер с интеграцией Ollama и сетевыми инструментами

Этот проект представляет собой MCP-сервер, интегрированный с локальными языковыми моделями Ollama. Сервер предоставляет два основных инструмента для автоматизации настройки сетевого оборудования:

1.  **Инструмент RAG (Retrieval-Augmented Generation)**: Выполняет семантический поиск релевантных команд конфигурации в локальной документации по типу оборудования (например, Cisco IOS) на основе запроса пользователя.
2.  **Инструмент выполнения**: Выполняет сгенерированные (найденные) команды на удаленном сетевом устройстве по протоколу SSH с использованием `asyncssh`.

Клиент представляет собой интерактивную консоль с улучшенным пользовательским интерфейсом (цвета, история команд, справка), через которую пользователь может общаться с моделью на естественном языке, описывая задачи по настройке сети.

## Требования

-   Python 3.10 или 3.11 (рекомендуется из-за совместимости с `numpy` и `sentence-transformers`)
-   Установленный и запущенный [Ollama](https://ollama.ai/)
-   Модель Ollama (например, `mistral`, `llama3`). Модель по умолчанию определяется переменной окружения `OLLAMA_MODEL` или равна `mistral`.
-   Устройство для тестирования (например, эмулятор вроде GNS3, Packet Tracer или реальное оборудование) с включённым SSH-доступом.

## Установка

1.  Клонируйте репозиторий:
    ```bash
    git clone <URL_ВАШЕГО_РЕПОЗИТОРИЯ>
    cd network_mcp_project
    ```

2.  (Рекомендуется) Создайте и активируйте виртуальное окружение:
    ```bash
    python -m venv venv
    source venv/bin/activate  # На Windows: venv\Scripts\activate
    ```

3.  Установите зависимости:
    ```bash
    pip install -r requirements.txt
    ```

4.  Убедитесь, что Ollama запущен и модель доступна. Например:
    ```bash
    ollama run mistral
    ```

## Настройка

1.  Убедьтесь, что папка `data/documentation/` содержит подпапки для нужных типов оборудования (например, `cisco_ios`, `juniper_junos`, `huawei`, `mikrotik`) с `.txt` файлами, содержащими документацию.
2.  (Опционально) Установите переменную окружения `OLLAMA_MODEL`, чтобы указать другую модель по умолчанию:
    ```bash
    export OLLAMA_MODEL=llama3
    ```

## Запуск

1.  **Запустите MCP-сервер** в отдельном терминале:
    ```bash
    python mcp_server.py
    ```
    Сервер будет доступен по адресу `http://localhost:8000` и автоматически проиндексирует документацию при запуске.

2.  **Запустите клиент** в новом терминале:
    ```bash
    python client.py
    ```

## Использование

-   В клиенте введите `help`, чтобы увидеть доступные команды.
-   Введите IP-адрес, имя пользователя и пароль от вашего сетевого устройства при первом запросе на настройку.
-   Укажите тип устройства (например, `cisco_ios`). Тип устройства чувствителен к регистру и должен совпадать с именем подпапки в `data/documentation/`.
-   Задавайте вопросы или задачи на естественном языке, например: "поменяй имя хоста на cisco1".
-   Клиент передаст запрос на сервер. Сервер:
    -   Проанализирует запрос.
    -   Использует RAG для поиска соответствующих команд в документации.
    -   Применит фильтрацию, чтобы повысить точность (например, ища ключевое слово `hostname` при запросе на изменение имени).
    -   Обработает команды (например, подставит значения из запроса).
    -   Проверит команды на безопасность.
    -   Вызовет инструмент выполнения.
    -   Инструмент выполнения подключится к устройству и попытается выполнить команды.
    -   Результат выполнения будет передан модели Ollama для генерации финального ответа.
-   Результат выполнения команд или сообщение об ошибке будет выведен в клиенте.
